#!/usr/bin/python3

import argparse
import copy
import io
import json
import os
import pprint
import re
import struct
import sys
        
from collections import OrderedDict

HEADER_HEADER = \
"""/***********************************************************
 **                                                       **
 **  This header file generated by msgidx. Do not alter.  **
 **                                                       **
 ***********************************************************/

"""

class MsgIdx(object):

    MAX_LANG = 9

    
    def __init__(self):

        self.progname = os.path.splitext(os.path.basename(sys.argv[0]))[0]
        
        # Get some defaults
        self.bbs_prefix = os.environ.get("BBSPREFIX")
        self.build_dir = os.environ.get("BUILDDIR")
        self.mbk_dir, self.header_dir = ".", "."

        if self.build_dir:
            self.mbk_dir = os.path.join(self.build_dir, "data/prompts")
            self.header_dir = "."

        elif self.bbs_prefix:
            self.mbk_dir = os.path.join(self.bbs_prefix, "data/prompts")
            self.header_dir = os.path.join(self.bbs_prefix, "include/prompts")

        # Allow overrides via the environment.
        self.mbk_dir = os.environ.get("MBKDIR", self.mbk_dir)
        self.header_dir = os.environ.get("MBKHDIR", self.header_dir)

        # Parse command line
        self.parse_command_line()


    def parse_command_line(self):
        """Parse command-line options."""
        p = argparse.ArgumentParser( description="""Compile legacy
        MajorBBS-like Message Block files (.msg).""")

        p.add_argument('-i', '--header-dir', metavar='PATH',
                       default=self.header_dir,
                       help="""Set the output directory for generated include files.
                       (default: %(default)s)""")

        p.add_argument('-m', '--mbk-dir', metavar='PATH',
                       default=self.mbk_dir,
                       help="""Set the output directory for generated .mbk files.
                       (default: %(default)s)""")

        p.add_argument('-j', '--json-dir', metavar='PATH',
                       default=self.mbk_dir,
                       help="""Set the output directory for generated JSON files.
                       (default: %(default)s)""")

        p.add_argument('-I', '--no-include', action="store_true",
                       help="""Don't write include (header) files.""")

        p.add_argument('-M', '--no-mbk', action="store_true",
                       help="""Don't write message block (.mbk) files.""")

        p.add_argument('-J', '--no-json', action="store_true",
                       help="""Don't write JSON files.""")

        p.add_argument('-e', '--encoding', metavar='ENCODING',
                       default="CP737", help="""Set the default encoding for parsing MBK files.
                       The default is CP737 because Megistos for historical reasons (Megistos
                       was originally seeded with AcroBase BBS message blocks in CP737.""")

        p.add_argument('-v', '--verbose', action="count",
                       default=0, help="""Increment verbosity. Specify multiple times for
                       even more increased verbosity.""")

        p.add_argument('-D', '--debug', action="store_true",
                       default=0, help="""Raise full Python exceptions on error.""")

        p.add_argument(metavar="FILE.MSG", dest="input_files",
                       nargs="*", help="Provide one or more .msg files to compile.")

        self.args = p.parse_args()


    def _msg(self, msgtype, msg, file=None, line=None):
        """Output an error, optionally about a file."""
        header = "{}: {}".format(self.progname, msgtype)
        if file is not None:
            header += ": {}".format(file)
            if line is not None:
                header += ":{}".format(line)

        print("{}: {}".format(header, msg), file=sys.stderr)


    def fatal(self, *args, exit_code=1, **kwargs):
        self._msg("error", *args, **kwargs)
        exit(exit_code)

    
    def error(self, *args, **kwargs):
        self._msg("error", *args, **kwargs)

    
    def warning(self, *args, **kwargs):
        self._msg("warning", *args, **kwargs)


    def info(self, *args, **kwargs):
        if self.args.verbose > 1:
            self._msg("info", *args, **kwargs)


    def debug(self, *args, **kwargs):
        if self.args.verbose > 2:
            self._msg("debug", *args, **kwargs)


    def trace(self, *args, **kwargs):
        if self.args.verbose > 3:
            self._msg("debug", *args, **kwargs)


    def run(self):
        for fname in self.args.input_files:
            try:
                f = open(fname, encoding=self.args.encoding)
                self.debug("opened {}.".format(fname))

            except OSError as e:
                self.error("opening {}: {}".format(fname, e))

            try:
                data = self.parse(fname, f)
                lang_data = self.compile(fname, data)
                self.write_files(fname, lang_data)

            except Exception as e:
                # Allow a full exception to be output.
                if self.args.debug:
                    raise


    def parse(self, fname, f):
        """Parse a Megistos MSG file. The format started off with MajorBBS
        MSG files, but has been expanded:

        The Major BBS format was designed to be displayed using a configuration
        editor that showed a short description of every setting and prompt,
        contained hints about its data type and limits (for strings and
        numbers), and of course the value itself.

        There were three ‘levels’. The config editor could show up to level 1,
        2, or 3. LEVEL1 was essential ‘ten-minute config’ settings, just the
        BBS name, telephone numbers, etc. LEVEL2 included all the configuration
        settings. LEVEL3 included advanced settings and all the BBS strings
        prompts that could be customised.

        Megistos only contains LEVEL2 and LEVEL3, but it adds LANG{}, which
        restarts LEVEL3 to add a second, third, etc. language (up to 10
        languages).

        LEVEL1 {}

        This is some help string for setting SETTINGNAME
        It may span multiple lines.

        SETTINGNAME {SETTING-VALUE} <TYPE> <LIMITS> <Short description>

        LEVEL2 {}
        
        This is some help string for setting SETTINGNAME
        It may span multiple lines.

        FOO {SETTING-VALUE} <TYPE> <LIMITS> <Short description>

        LEVEL3 {}

        BAR {A multiline prompt string.
        It can span multiple lines, and may escape closing braces using ~}, and tildes using ~~.
        } <TYPE> <LIMITS> <Short description>

        LANG {}

        ...

        LANGEND {}


        We implement the parser using two states:

        state 0: Parsing a help string. Terminated when { is found on a line.
        state 1: Parsing a config value. Terminate when } is found.

        """
        linenum = 1
        data = []
        state = 0
        helptext = ""
        valuetext = ""


        def parse_value(val):
            leftovers = None

            # Handle escaped sequences ~~ and ~}. Use \177 as a temporary placeholder.
            val = val.replace("~}", "\177")
            val = val.replace("~~", "~")

            # Is the end of the block visible? Match a } at the beginning of a
            # line, or a } after a character other than ~.
            m = re.match(r"^(.*)}\s*(.*)\s*$", val)
            if m:
                val, leftovers = m.groups()

            # Turn \177 placeholders to closing braces.
            val = val.replace("\177", "}")

            # Finally, translate substvar names like @BBS@ to "\177BBS\177",
            # but only if the previous character isn't ESC. (not sure why this
            # is the case, perhaps there are custom escape sequences that use @
            # as the second character)
            #
            # Substitution variables are always seen on a single line (no line
            # breaks allowed), so if we see the beginning of one we're
            # guaranteed to also see the end, and thus we can use a regexp.

            # This is pure horror, sorry.
            val = re.sub(r"(^|[^\x1b])@([A-Za-z0-9._-]+?)@", "\\1\x7f\\2\x7f", val)

            return val, leftovers

        name = None
        state0_match = re.compile(r"^(\S+)\s*{(.*)$")
        try:
            for linenum, line in enumerate(f, 1):
                #self.trace(repr(line), file=fname, line=linenum)

                if state == 0:
                    m = state0_match.match(line)
                    if m:
                        name, value = m.groups()
                        value, leftovers = parse_value(value)
                        self.trace("Name: {}, val: {}, leftovers: {}".format(
                            name, repr(value), repr(leftovers)), file=fname, line=linenum)

                        # Single-line setting?
                        if leftovers is not None:
                            helptext = helptext.strip("\n")
                            data.append((linenum, name, OrderedDict(value=value, help=helptext, desc=leftovers)))
                            helptext, valuetext = "", ""
                            self.trace("---")
                        else:
                            valuetext = ""
                            state = 1
                    else:
                        helptext += line.lstrip()
                        self.trace("Help: {}".format(repr(line)), file=fname, line=linenum)
                elif state == 1:
                    value, leftovers = parse_value(line)
                    valuetext += value
                    self.trace("Name: {}, val: {}, leftovers: {}".format(
                        name, repr(value), repr(leftovers)), file=fname, line=linenum)
                    if leftovers is not None:
                        helptext = helptext.strip("\n")
                        data.append((linenum, name, OrderedDict(value=valuetext, help=helptext, desc=leftovers)))
                        helptext, valuetext = "", ""
                        self.trace("---")
                        state = 0

        except UnicodeDecodeError as e:
            self.error("failed to decode using encoding {}. Wrong encoding?".format(
                self.args.encoding), file=fname, line=linenum)
            raise

        except Exception as e:
            self.error("whoops.")
            raise

        # We now have a list of entries. Go through them and build an array of
        # dicts, with data for each language present in the file. This will
        # leave out the level and language markers.
        self.debug("Building language table", file=fname)
        langdata = [ OrderedDict() ]
        langnum = 0
        level = 1
        langend = False
        n = 1
        self.enum = OrderedDict()
        for (linenum, name, datum) in data:
            if len(name) > 27:
                self.fatal("symbol {} (length {}) is longer than 27 characters".format(name, len(name)),
                           file=fname, line=linenum)

            if name in ["LEVEL1", "LEVEL2", "LEVEL3"]:
                level = int(name[-1])
                self.debug("found level #{} (language {})".format(level, langnum), file=fname, line=linenum)
                continue

            if name == "LANG":
                # Append a fresh blank index.
                langdata.append(OrderedDict())
                langnum += 1
                if langnum > self.MAX_LANG:
                    self.fatal("found start of language {} exeeding maximum of {}".format(langnum, self.MAX_LANG),
                               file=fname, line=linenum)
                self.debug("found language {}".format(langnum), file=fname, line=linenum)
                continue

            if name == "LANGEND":
                langend = True
                continue
            else:
                langend = False

            # Enumerate the symbol. This only happens for language 0, which
            # contains all the symbols. Symbols in subsequent languages may
            # only override those of language 0.
            if langnum == 0:
                self.trace("enumerating {} = {}".format(name, n), file=fname, line=linenum)
                self.enum[name] = n
                n += 1
            elif name not in self.enum:
                self.fatal("language {} includes symbol {} which was not defined in language 0.".format(
                    langnum, name), file=fname, line=linenum)
                
            # Add the datum to the current language.
            datum.update(language=langnum, level=level)
            langdata[-1][name] = datum

        if not langend:
            self.fatal("multilingual file, but the last entry wasn't LANGEND {}", file=fname)

        return langdata

        # print(json.dumps(langdata, indent=4))
        # exit(0)


    def compile(self, fname, langdata):
        """Parse hints, remove empty help, etc."""

        level = 0
        for langnum, data in enumerate(langdata):
            self.debug("compiling language {}".format(langnum), file=fname)
            for name, msg in data.items():
                if not msg['help']:
                    del(msg['help'])

                original_value = msg['value']
    
                # For string fields, the string value is in the braces and the hint
                # starts with an 'S' followed by the maximum length and the
                # description. Long prompts use 'T' instead, but the logic is the
                # same.
                #
                # All other fields have the description and value within the braces:
                #
                # Boolean values:
                #
                #     LONAUD {Make Audit Trail entry for each Log-on? YES} B
                #
                # Integer values: hint is "N min-value max-value" (I've also seen 'X' here)
                #
                #     TNLMAX {Maximum number of telnet lines occupied? 15} N 1 32767
                #
                # Choice values:
                #
                #     DFTPOP {Initial page-enable status at user signup STORE} E STORE OK ON OFF
    
                if name in ["LEVEL1", "LEVEL2", "LEVEL3"]:
                    level = int(name[-1])
                    continue
    
                if name in ["LANG", "LANGEND"]:
                    continue
    
                try:
                    # Parse optional conditionals
                    c_var, c_op, c_val, desc = re.match(r"^(?:\(([A-Z0-9_]+)([=])(.+?)\)\s+)?(.+)$",
                                                        msg['desc']).groups()
                    if c_var:
                        self.trace("Conditional: {} {} {}".format(c_var, c_op, c_val))
                    # Parse the rest of the descriptor
                    entrytype, desc = re.match(r"^([STBXNE])\s*(.+)?$", desc).groups()
    
                    if entrytype == "S":
                        maxlen, desc = re.match("^(\d+)\s+(.+)\s*", desc).groups()
                        msg.update(desc=desc, type="string", maxlen=int(maxlen))
                        #pprint.pprint(msg, width=200)
    
                    elif entrytype == "T":
                        msg.update(desc=desc, type="text")
                        #pprint.pprint(msg, width=200)
    
                    elif entrytype == "B":
                        desc, value = re.match("^(.*)\s+(yes|no|on|off|true|false|0|1)$", msg['value'], re.IGNORECASE).groups()
                        value = value.lower() in ['yes', 'on', 'true', '1']
                        msg.update(value=value, desc=desc, type="boolean")
                        #pprint.pprint(msg, width=200)
    
                    elif entrytype in "NX":
                        minval, maxval = re.match("^(\d+)\s+(\d+)\s*", desc).groups()
                        desc, value = re.match("^(.*)\s+(\d+)$", msg['value']).groups()
                        msg.update(value=int(value), desc=desc, type="int", min=int(minval), max=int(maxval))
                        #pprint.pprint(msg, width=200)
    
                    elif entrytype == "E":
                        choices = desc.split()
                        desc, value = re.match("^(.*)\s+(\S+)$", msg['value']).groups()
                        msg.update(value=value, desc=desc, type="choice", choices=choices)
                        #pprint.pprint(msg, width=200)
    
                    else:
                        self.error("Value of {} has unknown data type {}".format(name, entrytype))
    
                    # Add an enablement/visibility conditional
                    if c_var:
                        msg.update({"if": (c_var, c_op, c_val)})
                    msg['original_value'] = original_value
    
                except:
                    self.error("Value of {} has unknown descriptor {}".format(name, repr(msg['desc'])))
                    raise

        return langdata


    def write_json_file(self, langdata, json_fname):
        data = copy.deepcopy(langdata)
        for lang in data:
            for key in lang:
                try:
                    del lang[key]['original_value']
                except:
                    pass

        try:
            self.info("writing {}".format(json_fname))
            f = open(json_fname, "w", encoding="utf-8")
            json.dump(data, f)
            f.close()
            
        except Exception:
            self.error("failed to write {}".format(json_fname), file=fname)
            raise


    def write_include_file(self, filestem, header_fname):
        """Write the include file, but only if it's changed."""
        
        c_name = re.sub("[^A-Z0-9_]+", "_", filestem.upper())
        try:
            f = io.StringIO()
            f.write(HEADER_HEADER)
            f.write("#ifndef __{}_UNAMBIGUOUS__\n".format(c_name))
            # The tabs after #define are purposeful (output must match legacy msgidx)
            for name, val in self.enum.items():
                f.write("#define\t{} {}\n".format(name, val))
            f.write("#else\n")
            for name, val in self.enum.items():
                f.write("#define\t{}_{} {}\n".format(c_name, name, val))
            f.write("#endif /* __{}_UNAMBIGUOUS__ */\n".format(c_name))

            new_include_file = f.getvalue()

            # Done with the header file. Now see if the actual filesystem file is different.
            must_write = True
            if os.path.exists(header_fname):
                current_include_file = open(header_fname, "r", encoding="utf-8").read()
                must_write = new_include_file != current_include_file

            if must_write:
                self.info("writing {}".format(header_fname))
                with open(header_fname, "w", encoding="utf-8") as f:
                    f.write(new_include_file)
                    return True

            return False

        except Exception as e:
            self.error("failed to write {}".format(header_fname), file=header_fname)
            raise


    def generate_index(self, langdata, stringoffs):
        """Generate the string index. Also collect all strings as a side-effect."""
        # Sanity check
        assert langdata[0].keys() == self.enum.keys()

        # Generate the language 0 index. This one is simple.
        index0 = []
        ofs = stringoffs
        for key, msg in langdata[0].items():
            val = msg['original_value']
            index0.append((key, ofs, val))
            ofs += len(val) + 1

        # Now we have the base index, generate overrides for each language
        index = []
        for lang in langdata[1:]:
            for key, lang0_ofs, lang0_val in index0:
                # Does this language have an override for this key?
                if key in lang:
                    val = lang[key]['original_value']
                    index.append((key, ofs, val))
                    ofs += len(val) + 1
                else:
                    index.append((key, lang0_ofs, None))

        #pprint.pprint(index)

        return index0 + index
            

    def write_files(self, fname, langdata):
        filestem = os.path.splitext(os.path.basename(fname))[0]

        json_fname = os.path.join(self.args.json_dir, filestem + ".json")
        header_fname = os.path.join(self.args.header_dir, "mbk_{}.h".format(filestem))
        mbk_fname = os.path.join(self.args.mbk_dir, filestem + ".mbk")

        # Write a JSON file.
        if not self.args.no_json:
            self.write_json_file(langdata, json_fname)

        # Write the header file.
        if not self.args.no_include:
            self.write_include_file(filestem, header_fname)

        if self.args.no_mbk:
            return

        self.info("writing {}".format(mbk_fname))
        
        num_languages = len(langdata)
        num_symbols = len(self.enum)
        indexsize = num_languages * num_symbols

        mbk = io.BytesIO()

        # Write the magic number
        mbk.write(b"MMBK")

        # The size of the index, in entries, for all defined languages.
        # Sanity check
        x = struct.pack("I", indexsize)
        if len(x) != 4:
            self.fatal("runtime error: 8 bytes encoded for 4-byte integer.")
        mbk.write(x)

        # Write the language offsets. This is a table of where each of the
        # MAX_LANG languages starts in the index. Unused languages have a zero
        # offset (gracefully pointing back to language 0).
        for i in range(self.MAX_LANG):
            if i < num_languages:
                mbk.write(struct.pack("I", i * num_symbols))
            else:
                mbk.write(struct.pack("I", 0))

        # Sanity check
        assert mbk.tell() == struct.calcsize("I") * (2 + self.MAX_LANG)

        # Now come all the messages, null-terminated.
        indexofs = struct.calcsize("I") * (2 + self.MAX_LANG)
        stringofs = indexofs + (indexsize * 32)

        index = self.generate_index(langdata, stringofs)
        assert len(index) == indexsize

        string_data = b''
        for key, ofs, value in index:
            print(i, key, ofs)
            index_entry = struct.pack("I28s", ofs, key.encode(self.args.encoding))
            assert len(index_entry) == 32
            mbk.write(index_entry)
            if value is not None:
                string_data += value.encode(self.args.encoding) + b"\0"

        self.trace("indexofs: {}".format(indexofs))
        self.trace("indexsize: {}".format(indexsize))
        self.trace("stringofs: {}".format(stringofs))
        print(indexofs, indexsize, mbk.tell(), stringofs)

        assert mbk.tell() == stringofs
        mbk.write(string_data)

        with open(mbk_fname, "wb") as f:
            f.write(mbk.getvalue())

        # Now, generate an index table. We have up to MAX_LANG languages (the C
        # code assumes 10, we'll go with that.) The index table is a pointer of
        # file offsets to the beginning of each string in the file. The first
        # language (before LANG{} is seen) is expected to have all the strings
        # defined, and sets the ordering of strings.
        #
        # Subsequent languages override the strings, but their index is the
        # same size.


if __name__ == '__main__':
    MsgIdx().run()

# End of file.
